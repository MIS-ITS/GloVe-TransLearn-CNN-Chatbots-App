{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padSequence(feature, max_feature):\n",
    "    pad = np.zeros(max_feature-len(feature), dtype=np.float32)\n",
    "    feature = np.concatenate([feature, pad])\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordEmbedding(word, cursor):\n",
    "#     word = word.replace(\"'\", \"''\")\n",
    "    sql = \"\"\"select vec from term where term like %s\"\"\"\n",
    "    cursor.execute(sql, (str(word),))\n",
    "    data = cursor.fetchall()\n",
    "    if len(data) > 0:\n",
    "        decoded_vec = json.JSONDecoder().decode(data[0][0])\n",
    "        vec = np.asarray(decoded_vec, dtype=np.float32)\n",
    "        return True, vec\n",
    "    else:\n",
    "        return False, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myTokenizer(content, lower=True):\n",
    "    raw = content.split(' ')\n",
    "    remover = re.compile(\"[^a-zA-Z-]\")\n",
    "    \n",
    "    token = []\n",
    "    \n",
    "    for i in raw:\n",
    "        term = remover.sub('', i)\n",
    "        if lower == True:\n",
    "            term = term.lower()\n",
    "        token.append(term)\n",
    "    tokenized = filter(None, token)\n",
    "    \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangeInputMatrix(data, labels):\n",
    "    ftr_list = []\n",
    "    cls_list = []\n",
    "    \n",
    "    unique_labels = pd.unique(labels)\n",
    "    total_labels = len(unique_labels)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        cls = np.zeros((total_labels,), dtype=int)\n",
    "        cls_idx = np.where(unique_labels == labels[i])[0][0]\n",
    "        cls[cls_idx] = 1\n",
    "        \n",
    "        string = data[i].replace('\\n', '')\n",
    "        string = np.array(myTokenizer(string))\n",
    "\n",
    "        begin = True\n",
    "        for word in string:\n",
    "            stat, vec = getWordEmbedding(word, cursor)\n",
    "            if not stat:\n",
    "                continue\n",
    "            if begin:\n",
    "                begin = False\n",
    "                feature = vec\n",
    "            else:\n",
    "                feature += vec\n",
    "                # feature = np.concatenate([feature, vec])\n",
    "\n",
    "        feature = feature/np.linalg.norm(feature)\n",
    "        ftr_list.append(feature)\n",
    "        cls_list.append(cls)\n",
    "        \n",
    "    return np.array(ftr_list), np.array(cls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert into numpy array\n"
     ]
    }
   ],
   "source": [
    "print \"convert into numpy array\"\n",
    "df = pd.read_csv(\"schematics/data_target/data_target.csv\", sep=',', names=[\"documents\", \"labels\"])\n",
    "documents = df[\"documents\"].values\n",
    "labels = df[\"labels\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mysql.connector.connect(user=\"root\", password='namamuran', database=\"glove\")\n",
    "cursor = db.cursor(buffered=True)\n",
    "ftr, cls = arrangeInputMatrix(documents, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking len of array\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print \"checking len of array\"\n",
    "print len(documents) == len(ftr)\n",
    "print len(documents) == len(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"output/data-target-schematics/ftr-data-target.npy\", ftr)\n",
    "np.save(\"output/data-target-schematics/cls-data-target.npy\", cls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
